# ──────────────────────────────────────────────
# AuRE – environment configuration
# Copy this file to .env and fill in the values.
# ──────────────────────────────────────────────

# ── LLM provider ────────────────────────────
# Supported: "openai", "gemini", "alcf", "local" (Ollama / LM Studio / vLLM)
# If unset, AuRE auto-detects from whichever API key is present.
LLM_PROVIDER=openai

# ── API key ─────────────────────────────────
# Generic key (works for any provider):
LLM_API_KEY=sk-...
# Or use the provider-specific variable instead:
# OPENAI_API_KEY=sk-...
# GEMINI_API_KEY=...

# ── Model name ──────────────────────────────
# Defaults: openai → gpt-4o-mini, gemini → gemini-2.0-flash-lite,
#           alcf → gpt-oss-120b, local → llama3
LLM_MODEL=gpt-4o-mini

# ── Base URL (local / OpenAI-compatible only) ─
# Uncomment and set when using Ollama, LM Studio, vLLM, etc.
# LLM_BASE_URL=http://localhost:11434/v1

# ── Generation settings ─────────────────────
LLM_TEMPERATURE=0.0
LLM_TIMEOUT=120          # seconds to wait per LLM call

# ── ALCF inference endpoints ────────────────
# Set LLM_PROVIDER=alcf to use Argonne Leadership Computing Facility models.
# Docs: https://docs.alcf.anl.gov/services/inference-endpoints/
# ALCF_CLUSTER=sophia         # "sophia" (vLLM) or "metis" (SambaNova)
# ALCF_ACCESS_TOKEN=...       # Globus token – if unset, AuRE runs
#                              # inference_auth_token.py get_access_token
#
# Globus app / gateway IDs (defaults match the ALCF inference-endpoints repo;
# override only if ALCF publishes new client IDs).
# GLOBUS_APP_NAME=inference_app
# GLOBUS_AUTH_CLIENT_ID=
# GLOBUS_GATEWAY_CLIENT_ID=
# GLOBUS_GATEWAY_SCOPE=

# ── Fitting ──────────────────────────────────
# Method: "lm" (Levenberg-Marquardt, fast), "de" (Differential Evolution),
#         "dream" (MCMC with uncertainty quantification)
FIT_METHOD=dream
FIT_STEPS=1000             # number of MCMC / optimizer steps
FIT_BURN=1000              # burn-in steps (DREAM only)

# ── LangSmith tracing (optional) ────────────
# Set to "true" to send traces to LangSmith for debugging / monitoring.
# Requires the langsmith package (pip install langsmith).
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=ls-...
# LANGCHAIN_PROJECT=aure
